# Copyright 2025 The IREE Authors
#
# Licensed under the Apache License v2.0 with LLVM Exceptions.
# See https://llvm.org/LICENSE.txt for license information.
# SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception

name: PkgCI Test PJRT Metal plugin
on:
  workflow_call:
    inputs:
      write-caches:
        required: true
        type: string
  workflow_dispatch:
    inputs:
      write-caches:
        required: false
        type: string
        default: "1"

jobs:
  build_and_test:
    name: Metal PJRT (macos-latest-xlarge)
    runs-on: macos-latest-xlarge
    env:
      CCACHE_DIR: ${{ github.workspace }}/.ccache
    defaults:
      run:
        shell: bash
    steps:
      - name: Checking out repository
        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # v6.0.1
        with:
          submodules: true

      - name: Updating git submodules
        run: git submodule update --init --jobs 8 --depth 1

      - name: Clone JAX source
        run: git clone --depth=1 --branch add-iree-metal-donation-support https://github.com/robtaylor/jax.git ../jax

      # Select latest Xcode for Metal toolchain
      - name: Update Xcode command line tools path
        run: |
          sudo xcode-select --switch /Applications/Xcode.app/Contents/Developer
          xcrun metal --version
          xcrun metallib --version

      - name: Install uv
        uses: astral-sh/setup-uv@v5

      - name: Installing build requirements
        run: |
          brew install ninja ccache coreutils llvm
          # Symlink llvm-ar to /usr/local/bin (required by BaSpaCho's BundleStaticLibrary.cmake)
          # Apple's ar does not support MRI scripts (-M), so llvm-ar is needed
          sudo ln -sf "$(brew --prefix llvm)/bin/llvm-ar" /usr/local/bin/llvm-ar

      - name: Configure ccache
        run: |
          ccache --set-config=max_size=2G
          ccache --set-config=cache_dir=${{ github.workspace }}/.ccache
          ccache -z

      - name: Restore ccache
        uses: actions/cache@v4
        with:
          path: ${{ github.workspace }}/.ccache
          key: ccache-pjrt-metal-${{ runner.os }}-${{ runner.arch }}-${{ github.sha }}
          restore-keys: |
            ccache-pjrt-metal-${{ runner.os }}-${{ runner.arch }}-

      - name: Build IREE compiler
        env:
          CMAKE_C_COMPILER_LAUNCHER: ccache
          CMAKE_CXX_COMPILER_LAUNCHER: ccache
        run: |
          cmake -G Ninja -B compiler/build/b -S . \
            -DCMAKE_BUILD_TYPE=Release \
            -DCMAKE_C_COMPILER=clang \
            -DCMAKE_CXX_COMPILER=clang++ \
            -DCMAKE_C_COMPILER_LAUNCHER=ccache \
            -DCMAKE_CXX_COMPILER_LAUNCHER=ccache \
            -DIREE_BUILD_COMPILER=ON \
            -DIREE_BUILD_TESTS=OFF \
            -DIREE_BUILD_SAMPLES=OFF
          cmake --build compiler/build/b

      - name: Install compiler Python packages
        run: |
          cmake --install compiler/build/b \
            --prefix compiler/build/i \
            --component IREECompilerPythonPackages

      - name: Build and sync test environment
        run: |
          cd integrations/pjrt/test
          uv sync -vvv

      - name: ccache stats
        run: ccache -s

      - name: Verify installation
        run: |
          cd integrations/pjrt/test
          uv run python -c "
          import jax
          print(f'JAX version: {jax.__version__}')
          import iree._pjrt_libs.metal as m
          import os
          print(f'Metal PJRT plugin: {os.path.dirname(m.__file__)}')
          jax.config.update('jax_platforms', 'iree_metal')
          print(f'Metal devices: {jax.devices()}')
          "

      - name: Run Metal PJRT tests
        run: |
          cd integrations/pjrt/test

          echo "Running Metal-specific tests..."
          uv run python -m pytest test_metal.py -v || echo "Metal tests failed (possibly due to VM GPU limitations)"

          echo "Running Shardy dialect tests..."
          JAX_PLATFORMS=iree_metal uv run python test_shardy.py || echo "Shardy tests failed (possibly due to VM GPU limitations)"

      - name: Run comprehensive Metal tests
        run: |
          cd integrations/pjrt/test
          echo "Running comprehensive Metal test suite..."
          JAX_PLATFORMS=iree_metal uv run python test_metal_comprehensive.py || echo "Some comprehensive tests failed (see summary above)"

      - name: Run differential tests vs CPU
        run: |
          cd integrations/pjrt/test

          echo "Running differential tests (Metal vs CPU)..."
          diff_test_failed=0
          for test in test_add.py test_simple.py; do
            echo "Testing ${test}..."
            expected=$(JAX_PLATFORMS=cpu uv run python ${test}) || { echo "CPU baseline failed for ${test}"; diff_test_failed=1; continue; }
            actual=$(JAX_PLATFORMS=iree_metal uv run python ${test} 2>&1) || { echo "Metal execution failed for ${test} (possibly VM GPU limitation)"; diff_test_failed=1; continue; }
            if [ "$expected" != "$actual" ]; then
              echo "FAIL: Output mismatch for ${test}"
              echo "Expected: $expected"
              echo "Actual: $actual"
              diff_test_failed=1
            else
              echo "PASS: ${test}"
            fi
          done

          if [ $diff_test_failed -eq 1 ]; then
            echo "Some differential tests failed (possibly due to VM GPU limitations)"
          fi

      - name: Run Metal vs CPU benchmarks
        run: |
          cd integrations/pjrt/test
          echo "Running Metal vs CPU performance benchmarks..."
          JAX_PLATFORMS=cpu,iree_metal uv run python bench_metal_vs_cpu.py \
            --num-iterations 5 --sizes small --skip-sparse --output json \
            > /tmp/bench_results.json 2>/tmp/bench_stderr.log \
            || echo "Benchmarks failed (see stderr log)"
          cat /tmp/bench_stderr.log || true

      - name: Generate benchmark summary
        if: always()
        run: |
          python3 - <<'PYEOF'
          import json, os, sys

          summary_file = os.environ.get("GITHUB_STEP_SUMMARY", "/dev/stdout")
          results_path = "/tmp/bench_results.json"

          if not os.path.exists(results_path) or os.path.getsize(results_path) == 0:
              with open(summary_file, "a") as f:
                  f.write("## Metal vs CPU Benchmark\n\n")
                  f.write("> Benchmark did not produce results (possibly VM GPU limitation)\n\n")
              sys.exit(0)

          with open(results_path) as f:
              data = json.load(f)

          results = data.get("results", [])
          if not results:
              with open(summary_file, "a") as f:
                  f.write("## Metal vs CPU Benchmark\n\nNo results.\n\n")
              sys.exit(0)

          lines = []
          lines.append("## Metal vs CPU Benchmark\n")
          lines.append(f"**Platform:** {data.get('platform', 'unknown')} "
                        f"| **Iterations:** {data.get('num_iterations', '?')} "
                        f"| **Preset:** {data.get('sizes_preset', '?')}\n")
          lines.append("| Operation | Size | CPU (ms) | Metal (ms) | Speedup |")
          lines.append("|-----------|------|----------|------------|---------|")

          metal_faster = 0
          total = 0
          max_speedup = 0.0
          max_label = ""

          for r in results:
              op = r["operation"]
              size = r["size"]
              cpu_ms = r.get("cpu_median_ms")
              metal_ms = r.get("metal_median_ms")
              speedup = r.get("speedup")

              cpu_str = f"{cpu_ms:.2f}" if cpu_ms is not None else "error"
              metal_str = f"{metal_ms:.2f}" if metal_ms is not None else "error"

              if speedup is not None:
                  total += 1
                  sp_str = f"{speedup:.1f}x"
                  if speedup > 1.0:
                      metal_faster += 1
                      sp_str = f"**{sp_str}**"
                  if speedup > max_speedup:
                      max_speedup = speedup
                      max_label = f"{op} {size}"
              else:
                  sp_str = "n/a"

              lines.append(f"| {op} | {size} | {cpu_str} | {metal_str} | {sp_str} |")

          lines.append("")
          if total > 0:
              summary = f"Metal faster in **{metal_faster}/{total}** benchmarks"
              if max_speedup > 1.0:
                  summary += f", max speedup **{max_speedup:.1f}x** ({max_label})"
              lines.append(summary + "\n")

          with open(summary_file, "a") as f:
              f.write("\n".join(lines))

          # Also print table to logs
          for line in lines:
              print(line)
          PYEOF

      - name: Apply IREE Metal patches to JAX tests
        run: |
          cd ${{ github.workspace }}/../jax
          for patch in ${{ github.workspace }}/integrations/pjrt/test/patches/*.patch; do
            if [ -f "$patch" ]; then
              echo "Applying patch: $patch"
              patch -p1 < "$patch"
            fi
          done

      - name: Run JAX test suite
        timeout-minutes: 10
        run: |
          cd integrations/pjrt/test

          echo "Running JAX JitTest suite against IREE Metal..."
          JAX_PLATFORMS=iree_metal JAX_ENABLE_X64=0 uv run pytest \
            ${{ github.workspace }}/../jax/tests/api_test.py::JitTest \
            --tb=no -v 2>&1 | tee /tmp/jaxtest_output.txt || true

          # Extract results
          grep -c "PASSED" /tmp/jaxtest_output.txt > /tmp/metal_passing.txt || true
          grep -c "FAILED" /tmp/jaxtest_output.txt > /tmp/metal_failing.txt || true

          echo ""
          echo "=== JAX JitTest Results ==="
          passing=$(cat /tmp/metal_passing.txt 2>/dev/null || echo "0")
          failing=$(cat /tmp/metal_failing.txt 2>/dev/null || echo "0")
          echo "Passing tests: $passing"
          echo "Failing tests: $failing"

          if [ "$passing" -lt 75 ]; then
            echo "WARNING: Significant regression detected! Expected ~80 passing tests."
            exit 1
          fi

      - name: Upload test artifacts
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2
        if: always()
        with:
          name: test-and-bench-results
          path: |
            /tmp/jaxtest_output.txt
            /tmp/metal_passing.txt
            /tmp/metal_failing.txt
            /tmp/bench_results.json
          retention-days: 7

      - name: Post to Discord on Failure
        uses: sarisia/actions-status-discord@b8381b25576cb341b2af39926ab42c5056cc44ed # v1.15.5
        if: failure() && github.ref_name == 'main' && github.repository_owner == 'iree-org'
        with:
          webhook: ${{ secrets.DISCORD_WEBHOOK }}
          description: "The ${{ github.workflow }} workflow failed"
          url: "${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}/attempts/${{ github.run_attempt }}"
